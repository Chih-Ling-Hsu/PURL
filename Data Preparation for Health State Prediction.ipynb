{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:19:38.317231Z",
     "start_time": "2019-04-13T14:19:37.949816Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from utils.sql_functions import *\n",
    "\n",
    "def write_list_to_file(myList, output_path, var_name):\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"{}='''\".format(var_name))\n",
    "        f.write('\\n'.join([str(x) for x in myList]))\n",
    "        f.write(\"'''.split('\\\\n')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_user_context():\n",
    "    with closing(get_connection()) as conn: # ensure that the connection is closed        \n",
    "        statement = '''SELECT userId AS userID, height, weight, gender\n",
    "                        FROM user_info'''\n",
    "        user_data = query(conn, statement)\n",
    "    with closing(get_connection()) as conn: # ensure that the connection is closed\n",
    "        statement = '''SELECT userId AS userID, startTime, exerciseClassId, effectTime, age\n",
    "                        FROM user_exercise \n",
    "                        WHERE isMeetLeastEffectTime = \"Y\" '''\n",
    "        df = query(conn, statement)\n",
    "\n",
    "    df['time_window'] = [str(x)[:7] for x in df['startTime']]\n",
    "    del df['startTime']\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Group by 'userID', 'time_window', 'age'\n",
    "    dfs = [df.groupby(['userID', 'time_window', 'age']).agg({'effectTime' : ['mean', 'max', 'min', 'std', 'count']}).reset_index()]\n",
    "    dfs[0].columns = ['userID', 'time_window', 'age', \n",
    "                      'all_effectTime_mean', 'all_effectTime_max', 'all_effectTime_min', 'all_effectTime_std', 'all_count']\n",
    "    \n",
    "    # Group by 'userID', 'time_window', 'age', 'exerciseClassId'\n",
    "    df = df.groupby(['userID', 'time_window', 'age', 'exerciseClassId']).agg({'effectTime' : ['mean', 'max', 'min', 'std', 'count']}).reset_index()\n",
    "    df.columns = ['userID', 'time_window', 'age', 'exerciseClassId',\n",
    "                  'effectTime_mean', 'effectTime_max', 'effectTime_min', 'effectTime_std', 'count']\n",
    "    exerciseClassIdList = df['exerciseClassId'].unique()\n",
    "    dfs += [df[df['exerciseClassId'] == i].rename(columns={\"effectTime_mean\": \"effectTime_mean_{}\".format(i), \n",
    "                                                           \"effectTime_max\": \"effectTime_max_{}\".format(i), \n",
    "                                                           \"effectTime_min\": \"effectTime_min_{}\".format(i), \n",
    "                                                           \"effectTime_std\": \"effectTime_std_{}\".format(i), \n",
    "                                                           \"count\": \"count_{}\".format(i)}) \\\n",
    "                                          .drop(columns=['exerciseClassId']) for i in exerciseClassIdList]\n",
    "    \n",
    "    dfs = [df.set_index(['userID', 'time_window', 'age']) for df in dfs]\n",
    "    df = dfs[0].join(dfs[1:]).reset_index()\n",
    "    user_context = df.merge(user_data, on='userID', how='inner')\n",
    "    #print(user_context.isnull().sum())\n",
    "    \n",
    "    user_context = user_context.fillna(0)\n",
    "    return user_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RestHR Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_restHR_context():\n",
    "    with closing(get_connection()) as conn: #ensure that the connection is closed\n",
    "        statement = \"SELECT userId, restHRMeasureWay, createdTime, restHR FROM l_user_restHR\"\n",
    "        user_restHR = query(conn, statement)\n",
    "    user_restHR['createdMonth'] = [str(x)[:7] for x in user_restHR['createdTime']]\n",
    "    user_restHR[['userId', 'restHR']].groupby('userId').count().reset_index()\\\n",
    "                                     .rename(columns={'restHR': 'count'})\n",
    "    user_restHR[['userId', 'createdMonth', 'restHR']].groupby(['userId', 'createdMonth']).count().reset_index()\\\n",
    "                                                     .rename(columns={'restHR': 'count'})\n",
    "    restHR_context = user_restHR[['userId', 'createdMonth', 'restHR']].groupby(['userId', 'createdMonth'])\\\n",
    "                                                                      .agg({'restHR': ['mean', 'count']}).reset_index()\n",
    "    restHR_context.columns = ['userID', 'time_window', 'restHR_mean', 'restHR_count']\n",
    "    restHR_context = restHR_context.drop_duplicates()\n",
    "    return restHR_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_context = prepare_user_context()\n",
    "restHR_context = prepare_restHR_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine & Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(user_context, restHR_context, exerciseHR_context=None):\n",
    "    with closing(get_connection()) as conn: # ensure that the connection is closed        \n",
    "        statement = '''SELECT userId AS userID, birthday, gender, height, weight\n",
    "                        FROM user_info'''\n",
    "        _ = query(conn, statement)\n",
    "        user_dict = _.set_index(['userID']).to_dict('index')\n",
    "    \n",
    "    def calculate_age(user_dict, userID, end_date):\n",
    "        start_date = get_dict_value(user_dict, userID, 'birthday')\n",
    "        if type(end_date) == str:\n",
    "            end_date = datetime.strptime(end_date, \"%Y-%m\").date()\n",
    "        return relativedelta(end_date, start_date).years\n",
    "\n",
    "    def get_dict_value(user_dict, key, col, fill_val=None):\n",
    "        try:\n",
    "            return user_dict[key][col]\n",
    "        except KeyError:\n",
    "            return fill_val\n",
    "    \n",
    "    def fill_duration_context(data, context_dic, columns, duration_range, fill_val=0):\n",
    "        for col in columns:\n",
    "            for i in duration_range:\n",
    "                data['{}_m{}'.format(col, 1+i)] = [\n",
    "                    get_dict_value(context_dic, (user, str(m + relativedelta(months=i))[:7]), col, fill_val) \\\n",
    "                    for user, m in zip(data['userID'], data['time_window'])\n",
    "                ]\n",
    "        return data\n",
    "    \n",
    "    valid_HR = {\n",
    "        0:{\n",
    "            '(17, 25]':78, '(25, 35]':76, '(35, 45]':78, \n",
    "            '(45, 55]':77, '(55, 65]':77, '(65, 100]':76,\n",
    "        },\n",
    "        1:{\n",
    "            '(17, 25]':73, '(25, 35]':74, '(35, 45]':75,\n",
    "            '(45, 55]':76, '(55, 65]':75, '(65, 100]':73,\n",
    "        }\n",
    "    }\n",
    "    restHR_data = restHR_context.copy()\n",
    "    print(\"Original\", len(restHR_data['userID'].unique()))\n",
    "    \n",
    "    # Add user info\n",
    "    restHR_data['age'] = [calculate_age(user_dict, userID, end_date) for userID, end_date in \\\n",
    "                          zip(restHR_data['userID'], restHR_data['time_window'])]\n",
    "    for col in ['height', 'weight', 'gender']:\n",
    "        restHR_data[col] = [get_dict_value(user_dict, userID, col) for userID in restHR_data['userID']]\n",
    "    restHR_data = restHR_data.dropna()\n",
    "    print(\"Add user info\", len(restHR_data['userID'].unique()))\n",
    "    \n",
    "    # Age binning\n",
    "    age_intervals = [17, 25, 35, 45, 55, 65, 100]\n",
    "    restHR_data['AGE'] = pd.cut(restHR_data['age'], bins=age_intervals)\n",
    "    restHR_data['time_window'] = [datetime.strptime(x, '%Y-%m') for x in restHR_data['time_window']]\n",
    "    restHR_data = restHR_data.dropna()\n",
    "    print(\"Age binning\", len(restHR_data['userID'].unique()))\n",
    "\n",
    "    # Labeling - m1\n",
    "    restHR_dict = restHR_context.set_index(['userID', 'time_window']).to_dict('index')\n",
    "    restHR_data['belowAvg'] = [\n",
    "        hr > valid_HR[gender][str(age)] for hr,gender,age in zip(restHR_data['restHR_mean'], restHR_data['gender'], restHR_data['AGE'])\n",
    "    ]\n",
    "    restHR_data = restHR_data.drop_duplicates(['userID', 'time_window'])\n",
    "    restHR_data['restHR_count'] = [\n",
    "        get_dict_value(restHR_dict, (user, str(m)[:7]), 'restHR_count') \\\n",
    "        for user, m in zip(restHR_data['userID'], restHR_data['time_window'])\n",
    "    ]\n",
    "    print(\"Labeling - m1\", len(restHR_data[restHR_data['belowAvg'] == True]['userID'].unique()))\n",
    "    \n",
    "    # Labeling - m6\n",
    "    restHR_data['target_restHR_mean'] = [\n",
    "        get_dict_value(restHR_dict, (user, str(m + relativedelta(months=5))[:7]), 'restHR_mean') \\\n",
    "        for user, m in zip(restHR_data['userID'], restHR_data['time_window'])\n",
    "    ]\n",
    "    restHR_data['target_restHR_count'] = [\n",
    "        get_dict_value(restHR_dict, (user, str(m + relativedelta(months=5))[:7]), 'restHR_count') \\\n",
    "        for user, m in zip(restHR_data['userID'], restHR_data['time_window'])\n",
    "    ]\n",
    "    \n",
    "    # Select Users\n",
    "    data = restHR_data[restHR_data['belowAvg'] == True]\n",
    "    data = data[data['target_restHR_mean'].isnull() == False]\n",
    "    data['target_belowAvg'] = [\n",
    "        hr > valid_HR[gender][str(age)] for hr,gender,age in \\\n",
    "        zip(data['target_restHR_mean'], data['gender'], data['AGE'])\n",
    "    ]\n",
    "    print(\"Labeling - m6\", len(data['userID'].unique()))\n",
    "    \n",
    "    # Add exercise records\n",
    "    user_dict = user_context.set_index(['userID', 'time_window']).to_dict('index')\n",
    "    columns = list(set(user_context.columns) - set(['userID', 'time_window', 'age', 'height', 'weight', 'gender']))\n",
    "    data = fill_duration_context(data, user_dict, columns, range(1, 5), fill_val=0)\n",
    "    data['total_count'] = data[list(filter(lambda x: x.startswith('count_'), data.columns))].sum(axis=1)\n",
    "    data = data[data['total_count'] > 0]\n",
    "    \n",
    "    # Some statistics \n",
    "    for i in range(3):\n",
    "        print(\"At least {} exercise\".format(i+1), len(data[data['total_count'] > i]['userID'].unique()))\n",
    "    tmp  = data.copy()\n",
    "    for i in range(1, 5):\n",
    "        tmp = tmp[tmp['all_count_m{}'.format(i+1)] > 0]\n",
    "    print(\"At least 1 exercise per month\", len(tmp['userID'].unique()))\n",
    "    \n",
    "    # Add exerciseHR records\n",
    "    if exerciseHR_context is not None:\n",
    "        exerciseHR_dict = exerciseHR_context.set_index(['userID', 'time_window']).to_dict('index')\n",
    "        columns = list(set(exerciseHR_context.columns) - set(['userID', 'time_window']))\n",
    "        data = fill_duration_context(data, exerciseHR_dict, columns, range(1, 5), fill_val=None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Original', 7999)\n",
      "('Add user info', 7997)\n",
      "('Age binning', 7916)\n",
      "('Labeling - m1', 3404)\n",
      "('Labeling - m6', 289)\n",
      "('At least 1 exercise', 245)\n",
      "('At least 2 exercise', 235)\n",
      "('At least 3 exercise', 229)\n",
      "('At least 1 exercise per month', 155)\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data(user_context, restHR_context, exerciseHR_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID                   0\n",
       "time_window              0\n",
       "restHR_mean              0\n",
       "restHR_count             0\n",
       "age                      0\n",
       "height                   0\n",
       "weight                   0\n",
       "gender                   0\n",
       "AGE                      0\n",
       "belowAvg                 0\n",
       "target_restHR_mean       0\n",
       "target_restHR_count      0\n",
       "target_belowAvg          0\n",
       "all_effectTime_min_m2    0\n",
       "all_effectTime_min_m3    0\n",
       "all_effectTime_min_m4    0\n",
       "all_effectTime_min_m5    0\n",
       "effectTime_std_26_m2     0\n",
       "effectTime_std_26_m3     0\n",
       "effectTime_std_26_m4     0\n",
       "effectTime_std_26_m5     0\n",
       "effectTime_min_9_m2      0\n",
       "effectTime_min_9_m3      0\n",
       "effectTime_min_9_m4      0\n",
       "effectTime_min_9_m5      0\n",
       "all_effectTime_std_m2    0\n",
       "all_effectTime_std_m3    0\n",
       "all_effectTime_std_m4    0\n",
       "all_effectTime_std_m5    0\n",
       "effectTime_min_13_m2     0\n",
       "                        ..\n",
       "effectTime_mean_12_m5    0\n",
       "effectTime_mean_13_m2    0\n",
       "effectTime_mean_13_m3    0\n",
       "effectTime_mean_13_m4    0\n",
       "effectTime_mean_13_m5    0\n",
       "effectTime_mean_10_m2    0\n",
       "effectTime_mean_10_m3    0\n",
       "effectTime_mean_10_m4    0\n",
       "effectTime_mean_10_m5    0\n",
       "effectTime_mean_11_m2    0\n",
       "effectTime_mean_11_m3    0\n",
       "effectTime_mean_11_m4    0\n",
       "effectTime_mean_11_m5    0\n",
       "effectTime_mean_30_m2    0\n",
       "effectTime_mean_30_m3    0\n",
       "effectTime_mean_30_m4    0\n",
       "effectTime_mean_30_m5    0\n",
       "effectTime_min_1_m2      0\n",
       "effectTime_min_1_m3      0\n",
       "effectTime_min_1_m4      0\n",
       "effectTime_min_1_m5      0\n",
       "effectTime_mean_1_m2     0\n",
       "effectTime_mean_1_m3     0\n",
       "effectTime_mean_1_m4     0\n",
       "effectTime_mean_1_m5     0\n",
       "all_effectTime_max_m2    0\n",
       "all_effectTime_max_m3    0\n",
       "all_effectTime_max_m4    0\n",
       "all_effectTime_max_m5    0\n",
       "total_count              0\n",
       "Length: 334, dtype: int64"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('info/data.health_state_prediction_task.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:19:45.645254Z",
     "start_time": "2019-04-13T14:19:45.562104Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('info/data.health_state_prediction_task.csv', index_col=False, parse_dates=['time_window'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:19:45.781006Z",
     "start_time": "2019-04-13T14:19:45.761831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    352.000000\n",
       "mean      13.977273\n",
       "std       25.938431\n",
       "min        0.250000\n",
       "25%        2.750000\n",
       "50%        7.750000\n",
       "75%       17.312500\n",
       "max      362.750000\n",
       "Name: avg_count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['avg_count'] = [x/4 for x in data['total_count']]\n",
    "data['avg_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:19:46.917361Z",
     "start_time": "2019-04-13T14:19:45.958864Z"
    }
   },
   "outputs": [],
   "source": [
    "users_2015 = pd.read_csv('info/active_users.2015.csv')['userId'].unique()\n",
    "users_2016 = pd.read_csv('info/active_users.2016.csv')['userId'].unique()\n",
    "users_2017 = pd.read_csv('info/active_users.2017.csv')['userId'].unique()\n",
    "users_2018 = pd.read_csv('info/active_users.2018.csv')['userId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:19:49.618967Z",
     "start_time": "2019-04-13T14:19:49.597169Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_data = [data[(data['time_window'] >= '2015-01-01') & (data['time_window'] < '2016-01-01')], \n",
    "              data[(data['time_window'] >= '2016-01-01') & (data['time_window'] < '2017-01-01')], \n",
    "              data[(data['time_window'] >= '2017-01-01') & (data['time_window'] < '2018-01-01')], \n",
    "              data[(data['time_window'] >= '2018-01-01') & (data['time_window'] < '2019-01-01')] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:19:50.098644Z",
     "start_time": "2019-04-13T14:19:50.082916Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_data[0] = valid_data[0][valid_data[0]['userID'].isin(users_2015)]\n",
    "valid_data[1] = valid_data[1][valid_data[1]['userID'].isin(users_2016)]\n",
    "valid_data[2] = valid_data[2][valid_data[2]['userID'].isin(users_2017)]\n",
    "valid_data[3] = valid_data[3][valid_data[3]['userID'].isin(users_2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:26:25.452863Z",
     "start_time": "2019-04-13T14:26:25.440487Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sample_info(data):\n",
    "    data_dict = data[['userID', 'time_window']].to_dict('records')\n",
    "    for sample in data_dict:\n",
    "        m = sample['time_window']\n",
    "        sample['exercise_months'] = [str(m + relativedelta(months=i))[:7] for i in range(1, 5)]\n",
    "        del sample['time_window']\n",
    "    select_context = {}\n",
    "    for sample in data_dict:\n",
    "        if sample['userID'] in select_context:\n",
    "            select_context[sample['userID']] += sample['exercise_months']\n",
    "        else:\n",
    "            select_context[sample['userID']] = sample['exercise_months']\n",
    "    return select_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:20:01.624193Z",
     "start_time": "2019-04-13T16:20:01.582039Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.concat(valid_data[:2])\n",
    "data.to_csv('health_state_prediction/data/data.train.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:20:01.764531Z",
     "start_time": "2019-04-13T16:20:01.724563Z"
    }
   },
   "outputs": [],
   "source": [
    "select_context = get_sample_info(data)\n",
    "with open('info/samples.health_state_prediction.train.json', 'w') as f:\n",
    "    json.dump(select_context, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:20:04.431671Z",
     "start_time": "2019-04-13T16:20:04.404621Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.concat(valid_data[2:])\n",
    "data.to_csv('health_state_prediction/data/data.test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:20:04.568380Z",
     "start_time": "2019-04-13T16:20:04.519761Z"
    }
   },
   "outputs": [],
   "source": [
    "select_context = get_sample_info(data)\n",
    "with open('info/samples.health_state_prediction.test.json', 'w') as f:\n",
    "    json.dump(select_context, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
