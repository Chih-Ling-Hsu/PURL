{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T07:05:45.195299Z",
     "start_time": "2019-04-24T07:05:44.731230Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T02:53:28.010620Z",
     "start_time": "2019-04-20T02:53:27.884282Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('health_state_prediction/data/data.train.csv', index_col=False, parse_dates=['time_window'])\n",
    "test = pd.read_csv('health_state_prediction/data/data.test.csv', index_col=False, parse_dates=['time_window'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Behavior Extraction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T16:35:54.724123Z",
     "start_time": "2019-04-14T16:35:54.703083Z"
    }
   },
   "source": [
    "def show_exercise_behavior(data, r=1):\n",
    "    print(data.isnull().sum())\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        for j in range(r):\n",
    "            print(data['cluster_{}_m{}'.format(j, 1+i)].astype(str).describe())\n",
    "            print(data['cluster_{}_m{}'.format(j, 1+i)].astype(str).value_counts())\n",
    "            print('')\n",
    "            \n",
    "    Eb = list(filter(lambda x: x.startswith('cluster_0_'), data.columns))\n",
    "    display(data[['userID', 'time_window'] + Eb].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T02:53:28.103652Z",
     "start_time": "2019-04-20T02:53:28.013141Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_exercise_behavior(data, pattern_context):\n",
    "    def get_dict_value(user_dict, key, col, fill_val=None):\n",
    "        try:\n",
    "            return user_dict[key][col]\n",
    "        except KeyError:\n",
    "            return fill_val\n",
    "        \n",
    "    exercise_dict = pattern_context.set_index(['userID', 'time_window']).to_dict('index')\n",
    "    for col in pattern_context.columns:\n",
    "        if col in ['userID', 'time_window', 'cluster', 'periodicity']: continue\n",
    "        if 'std' in col: continue\n",
    "        for i in range(1, 5):\n",
    "            data['{}_m{}'.format(col, 1+i)] = [\n",
    "                get_dict_value(exercise_dict, (user, str(m + relativedelta(months=i))[:7]), col, fill_val=None) \\\n",
    "                for user, m in zip(data['userID'], data['time_window'])\n",
    "            ]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T02:53:28.198632Z",
     "start_time": "2019-04-20T02:53:28.107160Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_pure_features(data):\n",
    "    # Load user representations\n",
    "    df_train = pd.read_csv('health_state_prediction/data/exercise_patterns.clusters.train.csv')\n",
    "    df_test = pd.read_csv('health_state_prediction/data/exercise_patterns.clusters.test.csv')\n",
    "    pattern_context = pd.concat([df_train, df_test])#.fillna(0)\n",
    "    \n",
    "    # Add PURE features to data\n",
    "    data = extract_exercise_behavior(data, pattern_context)\n",
    "    data = data.fillna(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T02:53:28.789430Z",
     "start_time": "2019-04-20T02:53:28.202395Z"
    }
   },
   "outputs": [],
   "source": [
    "train_samples = add_pure_features(train)\n",
    "test_samples = add_pure_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T02:53:28.794893Z",
     "start_time": "2019-04-20T02:53:28.791149Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_data(data, file_path):\n",
    "    data['target'] = [0 if x==True else 1 for x in data['target_belowAvg']]\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    data.to_csv(file_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-20T02:53:28.972165Z",
     "start_time": "2019-04-20T02:53:28.797153Z"
    }
   },
   "outputs": [],
   "source": [
    "save_data(train_samples, 'health_state_prediction/data/train.csv')\n",
    "save_data(test_samples, 'health_state_prediction/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Experiments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:52:46.256468Z",
     "start_time": "2019-04-21T12:52:44.094570Z"
    }
   },
   "source": [
    "pattern_context = pd.concat([ptn_train, ptn_test])\n",
    "\n",
    "pattern_dict = pattern_context.set_index(['userID', 'time_window']).to_dict('index')\n",
    "pattern_dict = {k: list(v.values()) for k,v in pattern_dict.items()}\n",
    "\n",
    "with open('health_state_prediction/data/exercise_patterns.pkl', 'wb') as f:\n",
    "    pkl.dump(pattern_dict, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:48:00.105241Z",
     "start_time": "2019-04-21T12:48:00.094467Z"
    }
   },
   "source": [
    "pattern_dict[(10003, '2015-11')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PFPM + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:52:44.092412Z",
     "start_time": "2019-04-21T12:52:40.909078Z"
    }
   },
   "outputs": [],
   "source": [
    "ptn_train = pd.read_csv('health_state_prediction/data/exercise_patterns.train.csv', index_col=False)\n",
    "ptn_test = pd.read_csv('health_state_prediction/data/exercise_patterns.test.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:52:46.264704Z",
     "start_time": "2019-04-21T12:52:46.258756Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "K = 11\n",
    "Ep = list(filter(lambda x: x.startswith('pattern_'), ptn_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:52:46.573872Z",
     "start_time": "2019-04-21T12:52:46.266729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=11, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=K)\n",
    "pca.fit(ptn_train[Ep].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:52:46.635758Z",
     "start_time": "2019-04-21T12:52:46.579183Z"
    }
   },
   "outputs": [],
   "source": [
    "ptn_train_decomp = pca.transform(ptn_train[Ep].values)\n",
    "ptn_test_decomp = pca.transform(ptn_test[Ep].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:52:46.837623Z",
     "start_time": "2019-04-21T12:52:46.641295Z"
    }
   },
   "outputs": [],
   "source": [
    "ptn_train = ptn_train[['userID', 'time_window']]\n",
    "ptn_test = ptn_test[['userID', 'time_window']]\n",
    "for i in range(K):\n",
    "    ptn_train['pattern_{}'.format(i)] = [ptn[i] for ptn in ptn_train_decomp]\n",
    "    ptn_test['pattern_{}'.format(i)] = [ptn[i] for ptn in ptn_test_decomp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:52:46.872820Z",
     "start_time": "2019-04-21T12:52:46.839409Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern_context = pd.concat([ptn_train, ptn_test])\n",
    "\n",
    "pattern_dict = pattern_context.set_index(['userID', 'time_window']).to_dict('index')\n",
    "pattern_dict = {k: list(v.values()) for k,v in pattern_dict.items()}\n",
    "\n",
    "with open('health_state_prediction/data/exercise_patterns.decomposed.pkl', 'wb') as f:\n",
    "    pkl.dump(pattern_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPM + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T07:20:42.552093Z",
     "start_time": "2019-04-24T07:19:06.266932Z"
    }
   },
   "outputs": [],
   "source": [
    "ptn_train = pd.read_csv('health_state_prediction/data/tmp/exercise_patterns.train.csv', index_col=False)\n",
    "ptn_test = pd.read_csv('health_state_prediction/data/tmp/exercise_patterns.test.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T07:20:43.224883Z",
     "start_time": "2019-04-24T07:20:42.554185Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "K = 6\n",
    "Ep = list(filter(lambda x: x.startswith('pattern_'), ptn_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T07:20:44.469819Z",
     "start_time": "2019-04-24T07:20:43.227048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=K)\n",
    "pca.fit(ptn_train[Ep].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T07:20:44.817951Z",
     "start_time": "2019-04-24T07:20:44.471434Z"
    }
   },
   "outputs": [],
   "source": [
    "ptn_train_decomp = pca.transform(ptn_train[Ep].values)\n",
    "ptn_test_decomp = pca.transform(ptn_test[Ep].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T07:20:44.921902Z",
     "start_time": "2019-04-24T07:20:44.819769Z"
    }
   },
   "outputs": [],
   "source": [
    "ptn_train = ptn_train[['userID', 'time_window']]\n",
    "ptn_test = ptn_test[['userID', 'time_window']]\n",
    "for i in range(K):\n",
    "    ptn_train['pattern_{}'.format(i)] = [ptn[i] for ptn in ptn_train_decomp]\n",
    "    ptn_test['pattern_{}'.format(i)] = [ptn[i] for ptn in ptn_test_decomp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T07:20:45.068127Z",
     "start_time": "2019-04-24T07:20:44.923453Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern_context = pd.concat([ptn_train, ptn_test])\n",
    "\n",
    "pattern_dict = pattern_context.set_index(['userID', 'time_window']).to_dict('index')\n",
    "pattern_dict = {k: list(v.values()) for k,v in pattern_dict.items()}\n",
    "\n",
    "with open('health_state_prediction/data/tmp/exercise_patterns.decomposed.pkl', 'wb') as f:\n",
    "    pkl.dump(pattern_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## One-hot Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T13:28:13.688141Z",
     "start_time": "2019-04-14T13:28:13.684530Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def oh_encode(data, enc, categorical_cols):\n",
    "    encoded_cols = pd.DataFrame(enc.transform(data[categorical_cols]), columns=enc.get_feature_names(categorical_cols))\n",
    "    keep_cols = data.drop(categorical_cols, 1)\n",
    "    return pd.concat([keep_cols, encoded_cols], axis=1).reindex()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T13:28:13.828643Z",
     "start_time": "2019-04-14T13:28:13.689994Z"
    }
   },
   "source": [
    "for r in range(1, 4):\n",
    "    categorical_cols = list(filter(lambda x: x.startswith('cluster_'), train_samples[r].columns))\n",
    "    my_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    my_encoder.fit(train_samples[r][categorical_cols])\n",
    "    \n",
    "    train_samples[r] = oh_encode(train_samples[r], my_encoder, categorical_cols)\n",
    "    test_samples[r] = oh_encode(test_samples[r], my_encoder, categorical_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
